{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층신경망(MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 기본 Package 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # Graph\n",
    "\n",
    "# 데이터 가져오기\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "# 데이터 전처리\n",
    "from sklearn.preprocessing import StandardScaler    # 연속 변수 표준화\n",
    "from sklearn import preprocessing                   # 범주형 변수 수치화\n",
    "from sklearn.preprocessing import LabelEncoder      # 범주형 변수 수치화\n",
    "\n",
    "# 훈련/검증용 데이터 분리\n",
    "from sklearn.model_selection import train_test_split    # 훈련과 테스트를 위한 데이터 분리\n",
    "\n",
    "# 분류 모델\n",
    "# from sklearn.tree import DecisionTreeClassifier         # 의사결정나무\n",
    "# from sklearn.naive_bayes import GaussianNB            # 나이브 베이즈 분류\n",
    "# from sklearn.neighbors import KNeighborsClassifier      # K-최근접 이웃\n",
    "# from sklearn.ensemble import RandomForestClassifier   # 랜덤 포레스트\n",
    "# from sklearn.linear_model import LogisticRegression     # 로지스틱 회귀분석\n",
    "# from sklearn.svm import SVC                           # SVM(서포트벡터머신)\n",
    "from sklearn.neural_network import MLPClassifier      # 다층 인공신경망\n",
    "# from sklearn.ensemble import VotingClassifier           # 과반수 투표(Majority Voting) \n",
    "# from sklearn.ensemble import BaggingClassifier        # 배깅(Bagging) \n",
    "# from sklearn.ensemble import AdaBoostClassifier       # 부스팅(Boosting) \n",
    "\n",
    "# 모델 검정\n",
    "from sklearn.metrics import confusion_matrix, classification_report # 정오분류표\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer  # 정확도, 민감도 등\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc   # ROC 곡선\n",
    "\n",
    "# 최적화\n",
    "from sklearn.model_selection import cross_validate, cross_val_score  # 교차 타당도\n",
    "from sklearn.pipeline import make_pipeline  # 파이프라인 구축\n",
    "from sklearn.model_selection import learning_curve, validation_curve # 학습곡선, 검증곡선\n",
    "from sklearn.model_selection import GridSearchCV    # 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 가져오기\n",
    "\n",
    "### 2-1) 데이터 프레임으로 저장\n",
    "* csv 데이터를 dataframe으로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "\n",
    "# train data의 상위 5개 출력\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) 자료구조 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값 확인\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배열의 행, 열 갯수 확인\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 값 확인\n",
    "train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 데이터 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#범주형/연속형 변수 분리\n",
    "cat_col = ['department','region', 'education', 'gender','recruitment_channel','awards_won?']\n",
    "con_col = ['no_of_trainings', 'age', 'previous_year_rating',\n",
    "            'length_of_service','avg_training_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) ONE HOT ENCODING\n",
    "- 범주형 변수는 먼저 숫자로 변경해주어야 한다.\n",
    "- one-hot-encoding을 통해 string을 integer로 변환할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train,columns=cat_col,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df data의 상위 5개 출력\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2) 표준화\n",
    "- 표준화는 train data를 표준화한 포멧을 test data에도 wjrdyd\n",
    "- train data를 표준화할 때 사용한 평균과 표준편차를 test data에 적용하여 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#연속형 변수 스케일링\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train.loc[:,con_col])\n",
    "train.loc[:,con_col] = scaler.transform(train.loc[:,con_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3) null값 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값을 평균 값으로 대체\n",
    "train_df['previous_year_rating'].fillna(train_df['previous_year_rating'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null값 반영 여부 확인\n",
    "print(f'데이터 셋의 Null 값 개수:{train_df.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4) Data와 Target으로 분리\n",
    "- 필요한 data만 추출\n",
    "- data : `X`, taget : `y`로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "X = train_df.drop(['employee_id','is_promoted'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y=train_df['is_promoted']\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 훈련 / 검증용 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y,\n",
    "                     test_size = 0.3,   # test set의 비율\n",
    "                     random_state = 1,  # 무작위 시드 번호\n",
    "                     stratify = y)      # 결과 레이블의 비율대로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 모델 검정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1) 정오분류표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                        index=['True[0]','True[1]'],\n",
    "                        columns=['Predict[0]', 'Predict[1]'])\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도, 정밀도, 재현율, f1 score\n",
    "print(f'잘못 분류된 샘플 개수: {(y_test != y_pred).sum()}')\n",
    "print(f'정확도: {accuracy_score(y_test, y_pred):.3f}')\n",
    "print(f'정밀도: {precision_score(y_true=y_test, y_pred=y_pred):.3f}')\n",
    "print(f'재현율: {recall_score(y_true=y_test, y_pred=y_pred):.3f}')\n",
    "print(f'F1: {f1_score(y_true=y_test, y_pred=y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2) ROC 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, mlp.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr, '--', label=\"MLP\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "plt.plot([fpr], [tpr], 'r-', ms=10)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mlp = make_pipeline(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mlp.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = \\\n",
    "    learning_curve(estimator=pipe_mlp, # 수정\n",
    "                   X=X_train,\n",
    "                   y=y_train,\n",
    "                   train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                   cv = 10,\n",
    "                   n_jobs=1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='training accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, test_mean,\n",
    "         color='green', marker='o',\n",
    "         markersize=5, label='learning accuracy')\n",
    "\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-3) 검증 곡선으로 과대적합과 과소적합 조사하기\n",
    "* 과대 적합 : 파라미터가 많음 -> 파라미터 축소\n",
    "* 과소 적합 : 파라미터가 적음 -> 파라미터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = [1e-06, 1e-05, 0.0001, 0.001]\n",
    "\n",
    "train_scores, test_scores = \\\n",
    "    validation_curve(estimator=pipe_mlp, # 수정\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    param_name='mlpclassifier__alpha',\n",
    "                    param_range=param_range,\n",
    "                    cv = 10)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean,\n",
    "         color='blue', marker='o',\n",
    "         markersize=5, label='training accuracy')\n",
    "\n",
    "plt.fill_between(param_range,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean,\n",
    "         color='green', marker='o',\n",
    "         markersize=5, label='validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-4) 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range1 = [(5,5), (5,10), (10,5), (10,10)]\n",
    "param_range2 = [1e-06, 1e-05, 1e-04, 1e-03]\n",
    "param_grid = [{'mlpclassifier__hidden_layer_sizes': param_range1,\n",
    "              'mlpclassifier__alpha': param_range2}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_mlp,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Score : {gs.best_score_}\")\n",
    "print(f\"Best Param: {gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) 최적화 모델 검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = gs.best_estimator_\n",
    "best_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = y_pred.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                       index=['True[0]','True[1]'],\n",
    "                       columns=['Predict[0]', 'Predict[1]'])\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도, 정밀도, 재현율, f1 score\n",
    "print(f'잘못 분류된 샘플 개수: {(y_test != y_pred).sum()}')\n",
    "print(f'정확도: {accuracy_score(y_test, y_pred):.3f}')\n",
    "print(f'정밀도: {precision_score(y_true=y_test, y_pred=y_pred):.3f}')\n",
    "print(f'재현율: {recall_score(y_true=y_test, y_pred=y_pred):.3f}')\n",
    "print(f'F1: {f1_score(y_true=y_test, y_pred=y_pred):.3f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
