{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. 머신러닝 모델 정리\n",
    "\n",
    "### 의사결정나무\n",
    "\n",
    "* 목표 : 예측 변수를 기반으로 결과를 분류하거나 예측\n",
    "* 결정 규칙(decision rule)을 나무구조(tree)로 도표화하여 분류(classification)와 예측(prediction)을 수행하는 분석방법\n",
    "\n",
    "#### 주요 방법\n",
    "\n",
    "* Trees and Rule 구조\n",
    "    * 규칙(rules)은 나무 모델(tree diagram)로 표현\n",
    "    * 결과는 규칙(rules)으로 표현\n",
    "* 재귀적 분할(Recursive partitioning)\n",
    "    * 나무를 만드는 과정\n",
    "    * 그룹이 최대한 동질하도록 반복적으로 레코드를 하위 그룹으로 분리\n",
    "* 가지치기(Pruning the tree)\n",
    "    * 생성된 나무를 자르는 과정(정교화)\n",
    "    * 과적합을 피하기 위해 필요 없는 가지를 간단히 정리  \n",
    "\n",
    "#### 의사결정 나무 구분\n",
    "* 구분\n",
    "    * 분류나무 : 목표 변수가 범주형 변수\n",
    "    * 회귀나무 : 목표 변수가 수치형 변수 (예측 모델이 더욱 잘 되어 있어 거의 사용 X)\n",
    "* 재귀적 분할 알고리즘\n",
    "    * CART(Classification And Regression Tree)\n",
    "    * C4.5\n",
    "    * CHAID(Chi-square Automatic Interaction Detection)\n",
    "* 불순도(Impurity) 알고리즘\n",
    "    * Gini index\n",
    "    * Entropy index, 정보 이익(Informaion Gain)\n",
    "    * 카이제곱 통계량(Chi-Square statistic)\n",
    "\n",
    "#### 분류 나무(Classification Tree)\n",
    "\n",
    "* 목표 변수 : 범주형 변수 (분리)  \n",
    "* 예측 변수 : 범주형, 수치형 가능\n",
    "\n",
    "|분류 알고리즘|불순수도 지표|\n",
    "|---|---|\n",
    "|CART|Gini index|\n",
    "|C4.5|엔트로피, 정보이익, 정보이익비율|\n",
    "|CHAID|카이제곱 통계량|\n",
    "\n",
    "* 경향을 알아볼 때에도 사용 가능함\n",
    "\n",
    "![의사결정나무 정리](https://media.vlpt.us/images/noooooh_042/post/5209bd2f-65b0-4a35-b3ac-1ecd0d5d248c/image-20200925011308304.png)\n",
    "\n",
    "#### 의사결정나무 과정\n",
    "\n",
    "1. 나무 모델 생성\n",
    "2. 과적합 문제 해결\n",
    "3. 검증\n",
    "4. 해석 및 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
