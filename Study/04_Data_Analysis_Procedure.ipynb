{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 데이터 분석 절차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 01 ~ 03 에서 알아본 내용을 전체적으로 정리해보았다.\n",
    "\n",
    "해당 내용을 한번에 정리해두고, 이후 modeling 시 그냥 copy하여 사용할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Package 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # Graph\n",
    "\n",
    "# 데이터 가져오기\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 전처리\n",
    "from sklearn.preprocessing import StandardScaler    # 연속 변수 표준화\n",
    "from sklearn.preprocessing import LabelEncoder      # 범주형 변수 수치화\n",
    "\n",
    "# 훈련/검증용 데이터 분리\n",
    "from sklearn.model_selection import train_test_split    # 훈련과 테스트를 위한 데이터 분리\n",
    "\n",
    "# # 분류 모델\n",
    "# from sklearn.tree import DecisionTreeClassifier     # 의사결정나무\n",
    "# from sklearn.naive_bayes import GaussianNB      # 나이브 베이즈 분류\n",
    "# from sklearn.ensemble import RandomForestClassifier     # 랜덤 포레스트\n",
    "# from sklearn.ensemble import BaggingClassifier  # 앙상블\n",
    "# from sklearn.linear_model import LogisticRegression     # 로지스틱 회귀분석\n",
    "# from sklearn.svm import SVC      # SVM(서포트벡터머신)\n",
    "# from sklearn.neural_network import MLPClassifier    # 다층 인공신경망\n",
    "\n",
    "# 모델 검정\n",
    "from sklearn.metrics import confusion_matrix, classification_report # 정오분류표\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer  # 정확도, 민감도 등\n",
    "from sklearn.metrics import roc_curve   # ROC 곡선\n",
    "\n",
    "# 최적화\n",
    "from sklearn.model_selection import cross_validate  # 교차 타당도\n",
    "from sklearn.pipeline import make_pipeline  # 파이프라인 구축\n",
    "from sklearn.model_selection import learning_curve, validation_curve # 학습곡선, 검증곡선\n",
    "from sklearn.model_selection import GridSearchCV    # 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 가져오기\n",
    "\n",
    "#### 2-1) 데이터 프레임으로 저장\n",
    "* csv 데이터를 dataframe으로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv')\n",
    "test = pd.read_csv('../Data/test.csv')\n",
    "\n",
    "# train data의 상위 5개 출력\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 자료구조 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.info())\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배열의 행, 열의 갯수 확인\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column 값 확인\n",
    "train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2) Data와 Target으로 분리\n",
    "* 필요한 data만 추출\n",
    "* data : X , target : y 로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['is_promoted'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['is_promoted']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 데이터 전처리\n",
    "\n",
    "#### 3-1) data(X) 레이블 인코딩\n",
    "* 문자형 자료를 숫자(범주형)로 인코딩  \n",
    "* 숫자형 자료를 표준화  \n",
    "* 의사결정나무, 랜덤 포레스트, 나이브 베이즈 분류에서는 원본 데이터를 그대로 유지하면 됨  \n",
    "\n",
    "#### 3-2) Class(Target) 레이블 인코딩\n",
    "내가 가지고 있는 data의 target은 int형 값이므로 새롭게 인코딩 하지는 않았지만, 만약 레이블링 해야한다면 다음 code를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_le = LabelEncoder()\n",
    "# y = class_le.fit_transform(y)\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 훈련 / 검증용 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y,\n",
    "                     test_size = 0.3,   # test set의 비율\n",
    "                     random_state = 1,  # 무작위 시드 번호\n",
    "                     stratify = y)      # 결과 레이블의 비율대로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 모델 구축\n",
    "\n",
    "모델은 각각 직접 사용할 때 다시 호출하겠다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 모델 검정\n",
    "\n",
    "훈련용 데이터의 정확도와 검증용 데이터의 정확도를 비교하며 검증하는 것이 일반적이다.   \n",
    "이외에 검증용 데이터로 예측하는 방법도 존재한다.   \n",
    "`predict()` : class의 결과값으로 표시  \n",
    "`predict_proba()` : 확률 값으로 표시  \n",
    "\n",
    "\n",
    "**아직 model을 선정하지도, 돌려보지도 않았기 때문에 아래의 code는 오류가 난다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정오분류표\n",
    "`confusion_matrix()` : table을 만듦\n",
    "`y_test` : 실제 값 (행)\n",
    "`y_pred` : 예측 값 (열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                       index=['True[0]', 'True[1]'],\n",
    "                       columns = ['Predict[0]', 'Predict[1]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정확도, 민감도 확인\n",
    "* 정밀도와 재현율은 class가 2개인 경우에만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'잘못 분류된 sample 갯수 : {(y_test != y_pred).sum()}')\n",
    "print(f'정확도 : {accuracy_score(y_test, y_pred):.2f}%')\n",
    "print(f'정밀도 : {precision_score(y_true=y_test, y_pred=y_pred):.3f}%')\n",
    "print(f'재현율 : {recall_score(y_true=y_test, y_pred=y_pred):.3f}%')\n",
    "print(f'F1 : {f1_score(y_true=y_test, y_pred=y_pred):.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과값을 해석하는 방법\n",
    "\n",
    "|정오행렬|분류행렬|\n",
    "|---|---|\n",
    "|정확도|오류율|\n",
    "|TPR|FPR|\n",
    "|민감도|특이도|\n",
    "|재현율|정밀도|\n",
    "\n",
    "실제로는 같은 식을 사용하기에 아래 3가지는 같은 의미이다.   \n",
    "* TPR = 민감도(Sensitivity) = 재현율(Recall)   \n",
    "\n",
    "정확도는 class 0과 1 모두를 정확하게 분류함   \n",
    "오류율은 class 0과 1 모두를 정확하게 분류하지 못함  \n",
    "\n",
    "TPR(True Positive Rate)는 실제 class 1 중에 잘 맞춘 것을 의미    \n",
    "FPR(False Positive Rate)는 실제 calss 0 중에 못 맞춘 것을 의미    \n",
    "* 때문에 FPR은 `1-FPR`로 많이 사용한다.   \n",
    "*`1-FPR`은 특이도와 같다.*    \n",
    "\n",
    "민감도는 실제 class 1 중에 잘 맞춘 것을 의미하므로 TPR과 같다.   \n",
    "특이도는 실제 class 0 중에 잘 맞춘 것을 의미하므로 `1-FPR`이 된다.  \n",
    "\n",
    "재현율(Recall)은 **실제** class 1 중에 잘 맞춘 것이므로 `민감도`, `TPR`과 다 동일하게 사용할 수 있다.   \n",
    "정밀도(Precision)은 **예측** class 1 중에 잘 맞춘 것을 의미한다.   \n",
    "\n",
    "이것을 모두 합쳐 사용하는 개념이 `F1`이다.    \n",
    "실제로 잘 맞춘 것과 예측에서도 잘 맞춘 것을 한꺼번에 계산하는 것이다.    \n",
    "\n",
    "$$F1 = 2 \\times {{재현율\\times정밀도} \\over {재현율+정밀도}}$$    \n",
    "\n",
    "때문에 F1값이 높은 model의 성능이 뛰어나다고 이야기 할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC 곡선\n",
    "* decision_function 사용이 가능한 모델일 경우 : `tree.decision_function(X_test)`\n",
    "* decision_function 사용이 불가능한 모델일 경우 : `tree.predict_proba(X_test)[:,1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 둘 중 model에 맞는 구문을 활용\n",
    "# fpr, tpr, thresholes = roc_curve(y_test, tree.decision_function(X_test))\n",
    "fpr, tpr, thresholes = roc_curve(y_test, tree.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값 확인\n",
    "fpr, tpr, thresholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph 생성\n",
    "plt.plot(fpr, tpr, '--', label=\"Decision Tree\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"random guess\")\n",
    "plt.plot([fpr], [tpr], 'r--', ms=10)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
